{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera - Applied Data Science Capstone\n",
    "## Week 4\n",
    "### The Battle of Neighborhoods\n",
    "\n",
    "This notebook is part of the assignment of Week 4 of the Applied Data Science Capstone course on Coursera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ol>\n",
    "    <li>Introduction</li>\n",
    "    <li>Data</li>\n",
    "    <li>Methodology</li>\n",
    "    <li>XXX</li>\n",
    "    <li>XXX</li>\n",
    "</ol>\n",
    "    \n",
    "</div>\n",
    " \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Introduction</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universities in the UK are among the best worldwide - attracting thousands of students from around the globe per year. Major focus is usually given to bigger and more well-known cities like London, Cambridge or Oxford (Figure 1). \n",
    "\n",
    "<img src=\"UniRanking.PNG\" width=1000/>\n",
    "\n",
    "\n",
    "<center>Figure 1. University League Table 2020 <a href=https://www.thecompleteuniversityguide.co.uk/league-tables/rankings>[1]</a></center> </br>\n",
    "\n",
    "\n",
    "But what about other parts of the UK? One region for studying among some of the top universities, is the East Midlands, which is one of the nine official regions of England in the eastern part of central England. It comprises the counties of Derbyshire, Leicestershire, Rutland, Nottinghamshire, Lincolnshire and Northamptonshire and is home to the beautiful Peak District <a href=https://en.wikivoyage.org/wiki/East_Midlands>[2]</a>.\n",
    "\n",
    "\n",
    "Having experienced and currently still experiencing university life abroad and here in the UK, the focus of this project will be on providing students in the East Midlands some additional information for their life at university. While there are many things to consider when it comes to beginning your studies, one important aspect is the housing situation. For many, it is the first time living away from home, having to take responsibility for paying bills, etc. As such, we will be looking at places to rent, concentrating on the city of Nottingham. In addition, we will investigate other aspects that might be important for students when thinking about the location of their accommodation, such as entertainment, proximity to university, and public transport. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will require data about the available properties for rent in Nottingham, geo location data, and information about nearby things to do. Thus, we will use datasets from the following sources:\n",
    "\n",
    "1. Data from <a href=https://www.zoopla.co.uk/ rel=\"nofollow\" >Zoopla</a>. Zoopla is one of the UK's largest online real estate portals, where one can find properties for rent and sale. Easy access to these data for further processing are provided through their very own <a href=https://developer.zoopla.co.uk/ rel=\"nofollow\" >Zoopla API</a>. We use the python wrapper <a href=https://pypi.org/project/zoopla/ >Zoopla API</a> as it facilitates working with the API. One limitation that is to note here, is that the Zoopla API limits the size for each page of results to a 100. To have a better working dataset, the API call was repeated a few times for different result pages.\n",
    "\n",
    "2. To plot the properties in their appropriate districts, the <a href='https://www.opendatanottingham.org.uk/dataset.aspx?id=160' >data</a> for the electoral ward boundaries from 2019 for Nottingham City have downloaded as a json file and used in conjunction with a folium map. \n",
    "\n",
    "3. Using the <a href='https://developer.foursquare.com/' >Foursquare City Guide Developer API</a> provides us with things to do in Nottingham, such as a list of places to eat, shop and visit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>2.1 Load Dependencies</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (4.5.1)\n",
      "Requirement already satisfied: html5lib in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.9999999)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (4.9.1)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from html5lib) (1.14.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from beautifulsoup4) (2.0.1)\n",
      "Requirement already satisfied: seaborn in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from seaborn) (1.18.4)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from seaborn) (1.0.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn) (1.14.0)\n",
      "Requirement already satisfied: zoopla in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: marshmallow<3,>=2.13.6 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from zoopla) (2.21.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from zoopla) (2.23.0)\n",
      "Requirement already satisfied: enum34<2,>=1.1.6 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from zoopla) (1.1.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.11.1->zoopla) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.11.1->zoopla) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.11.1->zoopla) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.11.1->zoopla) (2.9)\n",
      "Libraries imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/marshmallow/schema.py:202: ChangedInMarshmallow3Warning: The dateformat option is renamed to datetimeformat in marshmallow 3.\n",
      "  ChangedInMarshmallow3Warning\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install lxml html5lib beautifulsoup4\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "!pip install zoopla\n",
    "from zoopla import Zoopla\n",
    "from json import JSONDecoder\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>2.2 Scrape required Data from Websites</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>_a. Zoopla_</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read API key from file\n",
    "with open(\"zooplaAuthentication.txt\",\"r\") as output:\n",
    "    lines=output.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make call to Zoopla API\n",
    "zoopla = Zoopla(api_key=lines[0])\n",
    "\n",
    "search_res = zoopla.property_listings({\n",
    "    'page_size': 100,\n",
    "    'page_number': 1,\n",
    "    'listing_status': 'rent',\n",
    "    'area': 'Nottingham',\n",
    "    'summarised': 'yes',\n",
    "    'radius': 0.1,\n",
    "    'new_homes': 'no'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>_b. Wikipedia_</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the following Wikipedia page to obtain the data that is in the table of postal codes \n",
    "urlWNG = 'https://en.wikipedia.org/wiki/NG_postcode_area'\n",
    "dfs = pd.read_html(urlWNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we have collected the data we need, let's take a closer look at them in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>3. Methodology</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyse Data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's have a look at the data we collected. For this, we will inspect the data and run some statistical analysis to better understand what we need to further do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_to follow..._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
